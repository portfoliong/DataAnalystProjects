{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4da6f8",
   "metadata": {},
   "source": [
    "# [1] - Declare Variables & Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce1fef",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f885857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty array to hold reviews\n",
    "unusedReviewArray = []\n",
    "reviewArray = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0f36d",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbb870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple enum class to improve text consistentcy and stop spelling mistakes.\n",
    "class Attitude:\n",
    "    NEGATIVE = 'NEGATIVE'\n",
    "    NEUTRAL = 'NEUTRAL'\n",
    "    POSITIVE = ' POSITIVE'\n",
    "\n",
    "\n",
    "#tuple class: so tuple review objects can be inserted into the 'reviewArray'\n",
    "class TupleReview:\n",
    "    #initalise self with 2 parameters\n",
    "    def __init__(self,text,rating):\n",
    "        self.text = text\n",
    "        self.rating = rating\n",
    "        self.attitude = self.attitude_calc()\n",
    "    \n",
    "    def attitude_calc(self):\n",
    "        if self.rating <= 2:\n",
    "            return Attitude.NEGATIVE \n",
    "        \n",
    "        elif self.rating == 3:\n",
    "            return Attitude.NEUTRAL\n",
    "        \n",
    "        else:\n",
    "            return Attitude.POSITIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e7d6e",
   "metadata": {},
   "source": [
    "# [2] - Get Data & Set it up as desired"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368c9758",
   "metadata": {},
   "source": [
    "### Import and Read Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a4dd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reviewerID\": \"A1F2H80A1ZNN1N\", \"asin\": \"B00GDM3NQC\", \"reviewerName\": \"Connie Correll\", \"helpful\": [0, 0], \"reviewText\": \"I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ago and just finished book 5.  Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved!  Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page!  These are books you won't be disappointed with.\", \"overall\": 5.0, \"summary\": \"Can't stop reading!\", \"unixReviewTime\": 1390435200, \"reviewTime\": \"01 23, 2014\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import json library, so JSON files can be operated on.\n",
    "import json\n",
    "\n",
    "#equate variable to data location\n",
    "amazon_review = r'C:\\Users\\Lord\\Desktop\\Data Analyst Portfolio Projects\\Project 3 - Amazon Book Data JSON\\AmazonBookReviews.json'\n",
    "\n",
    "#open the data, print a single JSON entry (line), then stop (break).\n",
    "with open(amazon_review) as data:\n",
    "    for eachline in data:\n",
    "        #test\n",
    "        print(eachline)\n",
    "        break\n",
    "        \n",
    "#below: full JSON line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d75dfec",
   "metadata": {},
   "source": [
    "### Create a dictionary variable to access specific JSON attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9650bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ago and just finished book 5.  Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved!  Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page!  These are books you won't be disappointed with. 5.0\n"
     ]
    }
   ],
   "source": [
    "with open(amazon_review) as data:\n",
    "    for eachline in data:\n",
    "        #dictionary variable uses JSON library to hold each line\n",
    "        eachReview = json.loads(eachline)\n",
    "        #test\n",
    "        print(eachReview['reviewText'],eachReview['overall'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f2589a",
   "metadata": {},
   "source": [
    "### Append desired JSON attributes to aforementioned array: [Old Method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416a8a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I really enjoyed this adventure and look forward to reading more of Robert Spire. I especially liked all the info on global warming. You did a good job on the research.', 4.0) \n",
      "\n",
      "I really enjoyed this adventure and look forward to reading more of Robert Spire. I especially liked all the info on global warming. You did a good job on the research. \n",
      "\n",
      "4.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(amazon_review) as data:\n",
    "    for eachline in data:\n",
    "        eachReview = json.loads(eachline)\n",
    "        #append desired attributes to array, as one object enlocsed with '()'\n",
    "        unusedReviewArray.append((eachReview['reviewText'],eachReview['overall']))\n",
    "       \n",
    "    #test 1: full entry\n",
    "    print(unusedReviewArray[3],\"\\n\")\n",
    "    \n",
    "    #test 2: review text\n",
    "    print(unusedReviewArray[3][0],\"\\n\")\n",
    "    \n",
    "    #test 3: review rating\n",
    "    print(unusedReviewArray[3][1],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cada69",
   "metadata": {},
   "source": [
    "### Append desired JSON attributes to aforementioned array: [New Method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7849dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.TupleReview object at 0x0000012565B4B4C0> \n",
      "\n",
      "I really enjoyed this adventure and look forward to reading more of Robert Spire. I especially liked all the info on global warming. You did a good job on the research. \n",
      "\n",
      "4.0 \n",
      "\n",
      " POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# We create a tuple class called 'tupleReview'. We can use this for efficiency\n",
    "\n",
    "with open(amazon_review) as data:\n",
    "    for eachline in data:\n",
    "        eachReview = json.loads(eachline)\n",
    "        #append: append tupleReview objects (from tupleReview) class w/ params\n",
    "        reviewArray.append(TupleReview(eachReview['reviewText'],eachReview['overall']))\n",
    "       \n",
    "    #test 1: full entry (returns object)\n",
    "    print(reviewArray[3],\"\\n\")\n",
    "    \n",
    "    #test 2: review text\n",
    "    print(reviewArray[3].text,\"\\n\")\n",
    "    \n",
    "    #test 3: review rating\n",
    "    print(reviewArray[3].rating,\"\\n\")\n",
    "    \n",
    "    #test 4: review attitude (calulated in the 'TupleReview' class)\n",
    "    print(reviewArray[3].attitude)\n",
    "#New Method: allows us better readability and promotes maintainance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763f6e23",
   "metadata": {},
   "source": [
    "# [3] - Import Sklearn Library & Split data into Test and Train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1331fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# note: Shift+Tab, after clicking on the method brings up documentation\n",
    "\n",
    "# array = reviewArray \n",
    "# test_size = (33% of array entries are for testing, 66% for training)\n",
    "# random_state = any integer equals same results for exact reproduction\n",
    "\n",
    "# create test/train variables to hold newly split data.\n",
    "trainingData, testData = train_test_split(reviewArray,test_size=0.33,random_state=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3fad05",
   "metadata": {},
   "source": [
    "# [4] - Split Data Further: Split text & attitude from the Test & Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3560ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen comprehension is used to split the text and attitude from both sets\n",
    "\n",
    "#extract the 'text' value from the training data and store it in variable etc.\n",
    "trainingData_text = [review.text for review in trainingData]\n",
    "trainingData_attitude = [review.attitude for review in trainingData]\n",
    "\n",
    "#extract the 'attitude' value from the test data and store it in variable etc.\n",
    "testData_text = [review.text for review in testData]\n",
    "testData_attitude = [review.attitude for review in testData]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ace6179",
   "metadata": {},
   "source": [
    "# [5] - CountVectorizer Import & Bag of Words Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c39423",
   "metadata": {},
   "source": [
    "### Import CountVectorizer from SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c595d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b66766",
   "metadata": {},
   "source": [
    "### Convert the text of the training data to numerics via vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aa73bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The text will be converted to binary through bag of words vectorization\n",
    "\n",
    "# store the CountVectorizer in a variable\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "#fit and transform the test & training data\n",
    "vectorized_trainingData_text = vectorizer.fit_transform(trainingData_text)\n",
    "vectorized_testData_text = vectorizer.transform(testData_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f1046",
   "metadata": {},
   "source": [
    "### Test: that text have been converted to vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90edf015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well child you did it again!!I haven't read anything by you I haven't enjoyed!!!!!!!!!!!!ALREADY bought the next book in this series and ready to sit down and start on a new adventure. GREAT JOB. LOVE YOUR WORK. \n",
      "\n",
      "  (0, 26110)\t1\n",
      "  (0, 4470)\t1\n",
      "  (0, 26738)\t2\n",
      "  (0, 6885)\t1\n",
      "  (0, 12831)\t1\n",
      "  (0, 945)\t1\n",
      "  (0, 11104)\t2\n",
      "  (0, 19287)\t1\n",
      "  (0, 1525)\t1\n",
      "  (0, 3753)\t1\n",
      "  (0, 8217)\t1\n",
      "  (0, 1193)\t1\n",
      "  (0, 3256)\t1\n",
      "  (0, 23952)\t1\n",
      "  (0, 16318)\t1\n",
      "  (0, 3155)\t1\n",
      "  (0, 12107)\t1\n",
      "  (0, 24069)\t1\n",
      "  (0, 21267)\t1\n",
      "  (0, 1354)\t2\n",
      "  (0, 19308)\t1\n",
      "  (0, 24285)\t1\n",
      "  (0, 21797)\t1\n",
      "  (0, 7419)\t1\n",
      "  (0, 22690)\t1\n",
      "  (0, 16813)\t1\n",
      "  (0, 16298)\t1\n",
      "  (0, 859)\t1\n",
      "  (0, 10595)\t1\n",
      "  (0, 13096)\t1\n",
      "  (0, 14434)\t1\n",
      "  (0, 26751)\t1\n",
      "  (0, 26496)\t1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(trainingData_text[0],\"\\n\")\n",
    "print(vectorized_trainingData_text[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f33b6bb",
   "metadata": {},
   "source": [
    "# [6] - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a07e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are multiple different types of classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4081d",
   "metadata": {},
   "source": [
    "### Import Linear SVM Classification from SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ec19151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector machine (SVM) is machine learning algorithm that analyzes \n",
    "# data for classification and regression analysis\n",
    "from sklearn import svm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e25720",
   "metadata": {},
   "source": [
    "### Equate SKLearn SVM to variable and fit the data to the machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0929690d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification support vector machine = SKLearn SVM package\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "# vectorized training text data (X) and training attitude data (Y)'fitted' \n",
    "clf_svm.fit(vectorized_trainingData_text,trainingData_attitude)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0749b13",
   "metadata": {},
   "source": [
    "### Test predict works the SVMs predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "087d3436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love description and appreciate philosophical musings....but...this was  like reading a speech by someone mildly intoxicated and very boring.you know those people who.keep going on even after you have given them every social cue to stop.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([' POSITIVE'], dtype='<U9')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(testData_text[1872])\n",
    "\n",
    "#Predict function used: test datas TEXT(X),\n",
    "# used to return predicted ATTITUDE(Y) as output\n",
    "clf_svm.predict(vectorized_testData_text[1872])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b081f8c",
   "metadata": {},
   "source": [
    "# [7] - Evaluating the accuracy of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cad9315a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148484848484848"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explanation:\n",
    "#- I vectorized the training-data-(text) and the test-data-(text)\n",
    "#- I fit the vectoriezed training-data-(text) and the training-data-(attitude)\n",
    "#- I predicted the test-data-(attitude) using the test-data-(text)  \n",
    "#- Below, I'm evaluating how well the predictions line up with the  ...\n",
    "#- ACTUAL test-data-(attitude)\n",
    "clf_svm.score(vectorized_testData_text,testData_attitude)\n",
    "\n",
    "#result = > 80% accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c8a4c",
   "metadata": {},
   "source": [
    "# [8] - F1 Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ab508",
   "metadata": {},
   "source": [
    "### Import F1 Scores from SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89352704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The F1 score shows the accuracy in a more indepth way than 'score'\n",
    "# It can be used to find uneven distributions of labels in data\n",
    "# It returns a score per label. i.e. 'POSITIVE' = 94% acc. 'NEGATIVE'=10% acc.\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c51b94",
   "metadata": {},
   "source": [
    "### Use F1 Score to measure the accuracy per Attitude (POS,NEG,NEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "845a881b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90792062, 0.36216216, 0.26059655])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note: Shift+Tab brings up documentation for f1_score, if you've clicked on it\n",
    "\n",
    "# Explanation:\n",
    "#- y_true = testData_Attitude | because thats the actualy results\n",
    "#- y_pred = clf_svm.predict(vectorized_testData_text) | because that returns our predictions for the (test) attitude\n",
    "#- average = None | because I don't want it to be averaged \n",
    "#- label = POS,NEG,NEU | because those are the indiviudal labels we want to see the accuracy of \n",
    "\n",
    "f1_score(testData_attitude,clf_svm.predict(vectorized_testData_text),average=None, labels=[Attitude.POSITIVE,Attitude.NEGATIVE,Attitude.NEUTRAL])\n",
    "\n",
    "#result: POS = 90% accuracy, NEG = 36% accuracy, NEU = 26% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae686df6",
   "metadata": {},
   "source": [
    "# [9] - Improving our model with F1 Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d73ec",
   "metadata": {},
   "source": [
    "### How do we improve our model? It's clearly lacking for NEG & NEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3613441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discovery:\n",
    "   # I found that the accuracy of predicting NEGATIVE & NEUTRAL scores is low\n",
    "    \n",
    "#Theory suggestion:\n",
    "    # This could be that the amount of training data for NEG and NEU is lower\n",
    "    # than POSITIVE by a margin\n",
    "#Test:\n",
    "    # check the make-up of the training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fecd15d",
   "metadata": {},
   "source": [
    "### Check the attitude make-up of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96cf44fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5613 \n",
      "\n",
      "444 \n",
      "\n",
      "643\n"
     ]
    }
   ],
   "source": [
    "#count postive entries in training data\n",
    "print(trainingData_attitude.count(Attitude.POSITIVE),\"\\n\")\n",
    "\n",
    "#count negative entries in training data\n",
    "print(trainingData_attitude.count(Attitude.NEGATIVE),\"\\n\")\n",
    "\n",
    "#count neutral entries in training data\n",
    "print(trainingData_attitude.count(Attitude.NEUTRAL))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c471332",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e633527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As seen from the above output, my theory has been proven. \n",
    "# The make-up of my vectorized-training-data-(text) has an imbalance\n",
    "# That imbalance makes the accuracy of prediction in regards to NEG & NEU low.\n",
    "# This must be rectified by balancing the make-up.\n",
    "\n",
    "# Another project, in the future, will go over how to equally distribute data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
